# ğŸ§  Le Super-Ensemble : SystÃ¨me de Recommandation Hybride AvancÃ©

> **ğŸ† Performance Finale : MAP@10 = 0.21181**  
> *ClassÃ© 1er sur la Leaderboard Kaggle (17.5%)*

---

## ğŸ“– 1. La Vision du Projet

Ce projet ne se contente pas d'appliquer un algorithme standard. Il construit une **architecture "Super-Ensemble"** conÃ§ue pour capturer les nuances subtiles du comportement des lecteurs que les modÃ¨les traditionnels manquent.

### Le DÃ©fi "Cold Start" & "Long Tail"
Les approches classiques (Collaboratif pur) Ã©chouent sur les livres rares (Long Tail) ou les nouveaux utilisateurs. Les approches de contenu (S-BERT) manquent de prÃ©cision sur les tendances virales.

### La Solution : Fusion de 5 Signaux ComplÃ©mentaires

| Signal | Technique UtilisÃ©e | Librairie / Outil | RÃ´le |
|--------|-------------------|-------------------|------|
| **SÃ©mantique** | Sentence-BERT | `sentence-transformers` (`all-MiniLM-L6-v2`) | Encode le texte (Titre + Auteur + Sujets) en vecteurs 384D |
| **Collaboratif** | TF-IDF + Time-Decay | `scikit-learn` (`TfidfTransformer`) | PondÃ¨re les interactions par rÃ©cence ($e^{-\lambda t}$) |
| **SÃ©quentiel** | Matrice de Co-visitation | `scipy.sparse` | Calcule $P(item_{next} \| item_{last})$ pour les sÃ©ries |
| **Latent** | SVD (Factorisation) | `scipy.sparse.linalg.svds` | RÃ©duit en 100 facteurs latents ($U \Sigma V^T$) |
| **Lexical** | BM25 / TF-IDF | `scikit-learn` (`TfidfVectorizer`) | SimilaritÃ© exacte sur les mots-clÃ©s (titres, auteurs) |

**Autres techniques :**
- **Boost Re-buy** : Favorise les items dÃ©jÃ  consultÃ©s (historique long-terme uniquement)
- **Boost PopularitÃ©** : LÃ©ger bonus pour les items "trending"
- **Cache Disque** : Embeddings S-BERT sauvegardÃ©s en `.npy` pour accÃ©lÃ©rer les relances

---

## âš™ï¸ 2. Architecture Technique

### Diagramme de Flux SimplifiÃ©

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DONNÃ‰ES D'ENTRÃ‰E                         â”‚
â”‚  interactions_train.csv (u, i, t)  +  items.csv (mÃ©tadonnÃ©es)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â–¼               â–¼               â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  S-BERT  â”‚    â”‚ TF-IDF   â”‚    â”‚   SVD    â”‚
          â”‚ Semantic â”‚    â”‚ Collab   â”‚    â”‚  Latent  â”‚
          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
               â”‚               â”‚               â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                       â–¼               â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   BM25      â”‚   â”‚ Sequential  â”‚
              â”‚  Keywords   â”‚   â”‚ Next-Item   â”‚
              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                     â”‚                 â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚   SCORE FINAL FUSIONNÃ‰ â”‚
                 â”‚  + Boost Re-buy        â”‚
                 â”‚  + Boost PopularitÃ©    â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
                    [ TOP-10 Recommandations ]
```

### Les Composants MathÃ©matiques

#### A. Le CÅ“ur Hybride (`alpha`)
Nous fusionnons une similaritÃ© collaborative ($S_{collab}$) et sÃ©mantique ($S_{sem}$) :
$$ S_{base} = \alpha \cdot S_{collab}(t) + (1-\alpha) \cdot S_{sem} $$
*   **Innovation** : $S_{collab}$ utilise une dÃ©croissance temporelle $e^{-\lambda \Delta t}$ avec deux demi-vies (1 jour et 250 jours) pour capturer Ã  la fois l'humeur du moment et les goÃ»ts profonds.

#### B. Le "Game Changer" SÃ©quentiel (`seq_weight`)
Bien que faible seul (MAP ~0.159), le modÃ¨le sÃ©quentiel capture une **orthogonalitÃ©** cruciale : la probabilitÃ© conditionnelle.
$$ P(i_{next} | i_{last}) \approx \log(1 + count(i_{last} \to i_{next})) $$
*Il corrige les erreurs du modÃ¨le sÃ©mantique qui peut recommander le Tome 3 avant le Tome 1.*

#### C. La Factorisation SVD (`svd_weight`)
DÃ©composition en valeurs singuliÃ¨res ($U \Sigma V^T$) de la matrice d'interactions.
*   **RÃ´le** : "Lissage" global. Il remplit les trous de la matrice sparse en connectant des communautÃ©s de lecteurs disjointes.

---

## ğŸ§ª 3. Journal des ExpÃ©riences & Analyse Critique

Voici les rÃ©sultats rÃ©els de nos itÃ©rations, montrant pourquoi l'Ensemble est nÃ©cessaire.

| # | Approche | MAP@10 | Statut | Analyse Critique |
|---|---|---|---|---|
| **â˜…** | **Super-Ensemble (Production)** | **0.2118** | **WINNER** | **La somme est supÃ©rieure aux parties.** |
| 7 | Coupled Semantic (Naive) | 0.2045 | Ã‰chec | Dilution du signal "Re-buy" par le bruit court-terme. |
| 8 | Semantic Hybrid (ChatGPT) | 0.2040 | MitigÃ© | L'enrichissement aide, mais l'architecture est le facteur limitant. |
| 0 | BM25 Probabilistic | 0.1954 | Baseline | Excellent sur les titres exacts, aveugle au sens. |
| 4 | Diversification (Auteur) | 0.1940 | Ã‰chec | Forcer la diversitÃ© nuit Ã  la prÃ©cision pure (Trade-off). |
| 6 | Filtre Items Rares | 0.1631 | Ã‰chec | La "Long Tail" contient de la valeur prÃ©dictive cachÃ©e. |
| **9** | **Sequential / Co-visitation** | **0.1593** | **Pivot** | **Faible score seul, mais apporte +2% dans l'ensemble.** |
| 1 | EASE (Linear Model) | 0.1067 | Ã‰chec | Overfitting massif sur ce dataset sparse. |
| 3 | Ensemble Short/Long Term | 0.1038 | Ã‰chec | Sans sÃ©mantique, le collaboratif pur plafonne. |
| 2 | SVD (Latent Factors) | 0.0400 | Faible | Trop abstrait seul, mais excellent rÃ©gularisateur. |

---

## ğŸ“‚ 4. Architecture ComplÃ¨te du Projet

### 4.1 Tableau des Fichiers et Dossiers

| Chemin | Type | Description |
|--------|------|-------------|
| **`data/`** | ğŸ“ Dossier | Contient toutes les donnÃ©es d'entrÃ©e et de cache. |
| `data/interactions_train.csv` | ğŸ“„ CSV | Historique des interactions utilisateur-item (colonnes: `u`, `i`, `t`). |
| `data/items.csv` | ğŸ“„ CSV | MÃ©tadonnÃ©es des livres (Title, Author, Subjects, Publisher). |
| `data/items_enriched_ai_turbo.csv` | ğŸ“„ CSV | Items enrichis via GPT-4o-mini (description, clean_author, category). |
| `data/sample_submission.csv` | ğŸ“„ CSV | Format attendu pour la soumission Kaggle. |
| `data/eda/` | ğŸ“ Dossier | Exports de l'analyse exploratoire (graphiques, stats). |
| `data/cache/` | ğŸ“ Dossier | Cache disque des embeddings S-BERT (accÃ©lÃ¨re les relances). |
| **`src/`** | ğŸ“ Dossier | Code source Python principal. |
| `src/models/production.py` | ğŸ Python | **CLASSE MAÃTRESSE** : `SemanticHybridRecommender` (Super-Ensemble). |
| `src/models/experimental.py` | ğŸ Python | Laboratoire d'expÃ©riences : BM25, EASE, SVD, Sequential, etc. |
| `src/models/svd.py` | ğŸ Python | Wrapper pour la factorisation SVD (`scipy.sparse.linalg.svds`). |
| `src/models/base.py` | ğŸ Python | Classe abstraite `BaseRecommender` (interface commune). |
| `src/models/__init__.py` | ğŸ Python | Exports des classes de modÃ¨les. |
| `src/preprocessing.py` | ğŸ Python | `DataLoader` : chargement, nettoyage, mapping IDs, split temporel. |
| `src/metrics.py` | ğŸ Python | Calcul vectorisÃ© du MAP@K (Mean Average Precision). |
| `src/tuning.py` | ğŸ Python | Script de Grid Search pour optimiser les hyperparamÃ¨tres. |
| `src/EnrichissementChatGPT.py` | ğŸ Python | Enrichissement des mÃ©tadonnÃ©es via API OpenAI (multithreadÃ©). |
| **`notebooks/`** | ğŸ“ Dossier | Notebooks Jupyter pour l'analyse et l'entraÃ®nement. |
| `notebooks/01_Data_Analysis.ipynb` | ğŸ““ Notebook | EDA : distributions, sparsitÃ©, long-tail, visualisations. |
| `notebooks/02_Main_Model_Training.ipynb` | ğŸ““ Notebook | **Pipeline principal** : entraÃ®nement + validation (MAP@10). |
| `notebooks/03_Main_Model_Submission_File_Generator.ipynb` | ğŸ““ Notebook | GÃ©nÃ©ration du fichier CSV de soumission Kaggle. |
| `notebooks/04_All_Experiments.ipynb` | ğŸ““ Notebook | **Journal des expÃ©riences** : teste tous les modÃ¨les isolÃ©ment. |
| **`app/`** | ğŸ“ Dossier | Application de dÃ©monstration. |
| `app/streamlit_app.py` | ğŸ Python | Interface web Streamlit pour les bibliothÃ©caires. |
| **`submission/`** | ğŸ“ Dossier | Fichiers de soumission gÃ©nÃ©rÃ©s. |
| `submission/submission_final.csv` | ğŸ“„ CSV | DerniÃ¨re soumission Kaggle (Top-10 par utilisateur). |
| `requirements.txt` | ğŸ“„ Texte | Liste des dÃ©pendances Python. |
| `README.md` | ğŸ“„ Markdown | Ce document. |

### 4.2 Comment Tester les ExpÃ©riences

Pour reproduire et comparer toutes nos expÃ©riences (BM25, EASE, SVD, Sequential, etc.) :

```bash
# 1. Ouvrir le notebook d'expÃ©riences
jupyter notebook notebooks/04_All_Experiments.ipynb

# 2. ExÃ©cuter toutes les cellules
# Le notebook va :
#   - Charger les donnÃ©es et crÃ©er un split 80/20
#   - EntraÃ®ner chaque modÃ¨le expÃ©rimental isolÃ©ment
#   - Afficher un tableau comparatif des scores MAP@10
```

**Structure du notebook `04_All_Experiments.ipynb` :**
1.  **Configuration** : Import des classes depuis `src/models/experimental.py`
2.  **Boucle d'expÃ©riences** : Chaque modÃ¨le est instanciÃ©, entraÃ®nÃ©, et Ã©valuÃ©
3.  **SynthÃ¨se** : Tableau final triÃ© par performance

**Ajouter une nouvelle expÃ©rience :**
1.  CrÃ©er une nouvelle classe dans `src/models/experimental.py` (hÃ©riter de `BaseRecommender`)
2.  L'importer dans `src/models/__init__.py`
3.  Ajouter un appel `run_experiment(MaClasse, "Nom", **params)` dans le notebook

---

## ğŸ“ˆ 5. Chronologie du Projet (2 Semaines)

| Jour | Phase | ActivitÃ©s | Score MAP@10 | DÃ©cision ClÃ© |
|------|-------|-----------|--------------|--------------|
| **J1** | ğŸ” Exploration | EDA, comprÃ©hension des donnÃ©es, statistiques de base | â€” | Identifier la sparsitÃ© (99.7%) et le problÃ¨me Long-Tail |
| **J2** | ğŸ” Exploration | Analyse des distributions temporelles, patterns de re-buy | â€” | DÃ©cider d'utiliser le Time-Decay |
| **J3** | ğŸ› ï¸ Baseline | ImplÃ©mentation TF-IDF collaboratif simple | 0.142 | Baseline fonctionnelle mais faible |
| **J4** | ğŸ› ï¸ ItÃ©ration | Ajout de S-BERT pour la similaritÃ© sÃ©mantique | 0.168 | +18% : le contenu aide significativement |
| **J5** | ğŸ› ï¸ ItÃ©ration | Fusion Hybride (Î± = 0.5) Collab + SÃ©mantique | 0.182 | Synergie confirmÃ©e |
| **J6** | ğŸ§ª ExpÃ©riences | Test BM25, EASE, SVD isolÃ©s | 0.04-0.19 | Aucun modÃ¨le seul ne dÃ©passe l'hybride |
| **J7** | ğŸ› ï¸ ItÃ©ration | Ensemble multi-demi-vies (1j + 250j) | 0.195 | Capturer court-terme ET long-terme |
| **J8** | ğŸ§ª ExpÃ©riences | Test diversification, filtrage items rares | 0.16-0.19 | Contraintes = perte de prÃ©cision |
| **J9** | ğŸ’¡ Breakthrough | DÃ©couverte du boost "Re-buy DÃ©corrÃ©lÃ©" | 0.201 | Ne pas diluer les favoris historiques |
| **J10** | ğŸ§ª ExpÃ©riences | Enrichissement ChatGPT des mÃ©tadonnÃ©es | 0.204 | AmÃ©lioration marginale |
| **J11** | ğŸ’¡ Breakthrough | **ImplÃ©mentation Sequential (Co-visitation)** | **0.211** | **+5% : Le Game Changer !** |
| **J12** | ğŸ”§ Tuning | Grid Search sur tous les poids (Î±, seq, bm25, svd) | 0.2118 | ParamÃ¨tres optimaux trouvÃ©s |
| **J13** | ğŸ“¦ Finalisation | Nettoyage du code, documentation, tests | 0.2118 | Code prÃªt pour production |
| **J14** | ğŸš€ Livraison | Soumission Kaggle + RÃ©daction README | **0.2118** | **ğŸ† 1Ã¨re Place !** |

---

## ğŸš€ 6. Guide d'Utilisation

### Installation
```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### Reproduire la Performance (0.211)
1.  Ouvrez `notebooks/02_Main_Model_Training.ipynb`.
2.  ExÃ©cutez toutes les cellules.
3.  Le modÃ¨le s'entraÃ®nera avec les hyperparamÃ¨tres optimaux (`alpha=0.5`, `half_life=[1, 250]`, `seq_weight=0.3`).

### GÃ©nÃ©rer la Soumission Kaggle
```bash
jupyter notebook notebooks/03_Main_Model_Submission_File_Generator.ipynb
```
*GÃ©nÃ¨re `submission/submission_final.csv` entraÃ®nÃ© sur 100% des donnÃ©es.*

---

## ğŸ–¥ï¸ 7. Application Streamlit â€” BiblioRec

Une application web complÃ¨te a Ã©tÃ© dÃ©veloppÃ©e pour permettre aux **bibliothÃ©caires** d'utiliser le modÃ¨le de recommandation de maniÃ¨re intuitive.

### 7.1 Lancement

```bash
# Depuis la racine du projet
streamlit run app/streamlit_app.py
```

L'application s'ouvre automatiquement dans votre navigateur Ã  l'adresse `http://localhost:8501`.

### 7.2 FonctionnalitÃ©s par Onglet

| Onglet | IcÃ´ne | FonctionnalitÃ© | Cas d'Usage |
|--------|-------|----------------|-------------|
| **Accueil** | ğŸ  | Dashboard avec KPIs + Recherche rapide | Vue d'ensemble de la bibliothÃ¨que |
| **Recommander Ã  un Usager** | ğŸ‘¤ | Recommandations personnalisÃ©es pour un usager existant | "Que proposer Ã  l'usager #1234 ?" |
| **DÃ©couverte (Cold Start)** | ğŸ” | Recherche sÃ©mantique par description textuelle | Nouvel usager : "J'aime les thrillers nordiques" |
| **Livres Similaires** | ğŸ“– | Trouver des livres similaires Ã  un titre donnÃ© | "Quoi lire aprÃ¨s Harry Potter ?" |
| **Statistiques** | ğŸ“Š | Graphiques : Top auteurs, distribution, sparsitÃ© | Analyse de la collection |
| **Ã€ Propos** | â„¹ï¸ | Documentation technique du modÃ¨le | Comprendre l'algorithme |

### 7.3 Guide d'Utilisation DÃ©taillÃ©

#### ğŸ‘¤ Recommander Ã  un Usager (Cas Principal)

1. **SÃ©lectionner l'usager** : Recherchez par ID ou parcourez la liste
2. **Configurer les options** :
   - â˜‘ï¸ *Exclure les livres dÃ©jÃ  empruntÃ©s* (recommandÃ©)
   - ğŸ“š *Max par auteur* : Limite la redondance (ex: max 2 livres du mÃªme auteur)
   - ğŸ’¡ *Afficher les explications* : Montre pourquoi chaque livre est recommandÃ©
3. **Cliquer sur "GÃ©nÃ©rer les recommandations"**
4. **RÃ©sultats** :
   - Liste des Top-K livres avec titre, auteur, explication
   - Bouton ğŸ‘ pour donner du feedback (sauvegardÃ© dans `data/feedback_log.csv`)
   - Bouton ğŸ“¥ pour tÃ©lÃ©charger la liste en CSV

#### ğŸ” DÃ©couverte â€” Cold Start

Pour les **nouveaux usagers** sans historique :
1. DÃ©crivez leurs goÃ»ts en texte libre :
   > *"Romans policiers scandinaves, ambiance sombre, enquÃªtes psychologiques"*
2. Le modÃ¨le S-BERT encode cette description et trouve les livres les plus proches sÃ©mantiquement

#### ğŸ“Š Statistiques

- **Top 15 Auteurs** : Graphique horizontal des auteurs les plus empruntÃ©s
- **Distribution des emprunts** : Histogramme du nombre d'emprunts par usager
- **Jauges** :
  - *SparsitÃ©* : % de la matrice UserÃ—Item qui est vide (~99.7%)
  - *Couverture* : % des livres ayant au moins 1 emprunt
  - *Usagers actifs* : % des usagers ayant au moins 1 emprunt

### 7.4 Configuration (Sidebar)

| ParamÃ¨tre | DÃ©faut | Description |
|-----------|--------|-------------|
| **Alpha** | 0.5 | Balance Collaboratif â†” SÃ©mantique (0 = 100% sÃ©mantique) |
| **Demi-vie court** | 1 jour | Capture les tendances immÃ©diates |
| **Demi-vie long** | 250 jours | Capture les goÃ»ts de fond |
| **Top-K** | 10 | Nombre de recommandations Ã  afficher |
| **MÃ©tadonnÃ©es enrichies** | Off | Utiliser `items_enriched_ai_turbo.csv` (GPT-4) |

### 7.5 Captures d'Ã‰cran (Description)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“š BiblioRec â€” SystÃ¨me de Recommandation Intelligent       â”‚
â”‚  PropulsÃ© par le Super-Ensemble                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [ğŸ  Accueil] [ğŸ‘¤ Usager] [ğŸ” DÃ©couverte] [ğŸ“– Similaires]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  12,847  â”‚  â”‚  15,123  â”‚  â”‚  98,456  â”‚  â”‚   7.6    â”‚   â”‚
â”‚   â”‚ Usagers  â”‚  â”‚  Livres  â”‚  â”‚ Emprunts â”‚  â”‚ Moy/User â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â”‚   ğŸ” Recherche Rapide: [_________________]                  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š 8. RÃ©fÃ©rences Bibliographiques

Notre approche s'appuie sur des travaux de recherche reconnus dans le domaine des systÃ¨mes de recommandation :

| Concept | RÃ©fÃ©rence |
|---------|-----------|
| **Sentence-BERT** | Reimers & Gurevych (2019) - *"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"* - EMNLP |
| **Time-Decay Collaborative** | Koren (2009) - *"Collaborative Filtering with Temporal Dynamics"* - KDD |
| **BM25** | Robertson & Zaragoza (2009) - *"The Probabilistic Relevance Framework: BM25 and Beyond"* - Foundations and Trends in IR |
| **SVD pour RecSys** | Funk (2006) - *"Netflix Update: Try This at Home"* - Blog post (Netflix Prize) |
| **Ensemble Methods** | Bell & Koren (2007) - *"Lessons from the Netflix Prize Challenge"* - SIGKDD Explorations |
| **Hybrid Recommenders** | Burke (2002) - *"Hybrid Recommender Systems: Survey and Experiments"* - User Modeling and User-Adapted Interaction |

---

## ğŸ”¬ 9. Limites & Perspectives

### Limites Actuelles

| Limite | Description | Impact |
|--------|-------------|--------|
| **Cold Start Utilisateurs** | Nouveaux utilisateurs sans historique | Fallback sur popularitÃ© uniquement |
| **Cold Start Items** | Nouveaux livres sans interactions | DÃ©pend uniquement de S-BERT (contenu) |
| **Biais de PopularitÃ©** | Items populaires sur-reprÃ©sentÃ©s | Peut nuire Ã  la dÃ©couverte (sÃ©rendipitÃ©) |
| **ScalabilitÃ© MÃ©moire** | Matrice de similaritÃ© S-BERT dense (NÃ—N) | Limite pratique ~100K items |
| **DonnÃ©es Implicites** | Pas de feedback nÃ©gatif explicite | On ne sait pas ce que l'utilisateur n'aime PAS |

### AmÃ©liorations Futures

1. **Graph Neural Networks** : IntÃ©grer LightGCN ou PinSage pour mieux capturer les relations utilisateur-item dans un graphe
2. **Transformers SÃ©quentiels** : Remplacer la co-visitation par SASRec ou BERT4Rec pour une modÃ©lisation sÃ©quentielle plus fine
3. **Multi-Objectif** : Optimiser simultanÃ©ment prÃ©cision + diversitÃ© + nouveautÃ©
4. **A/B Testing** : Valider les gains offline (MAP@10) par des mÃ©triques online (CTR, temps de lecture)
5. **ExplicabilitÃ©** : Ajouter des justifications ("RecommandÃ© car vous avez aimÃ© X")

---

## ğŸ“Š 10. Choix de la MÃ©trique : Pourquoi MAP@10 ?

### Comparaison des MÃ©triques de Ranking

| MÃ©trique | Formule SimplifiÃ©e | Avantage | InconvÃ©nient |
|----------|-------------------|----------|--------------|
| **MAP@K** | Moyenne des prÃ©cisions aux positions de hit | PÃ©nalise les erreurs en haut du ranking | Ignore la diversitÃ© |
| **NDCG@K** | Gain pondÃ©rÃ© par $\log_2(position)$ | PondÃ©ration plus fine | Plus complexe Ã  interprÃ©ter |
| **Recall@K** | $\frac{\|hits\|}{\|relevant\|}$ | Simple et intuitif | Ignore totalement l'ordre |
| **MRR** | $\frac{1}{rang_{premier\_hit}}$ | Focus sur le 1er rÃ©sultat | Ignore les autres positions |
| **Hit Rate@K** | 1 si au moins 1 hit, 0 sinon | TrÃ¨s simple | Trop binaire |

### Notre Choix : MAP@10

$$MAP@K = \frac{1}{|U|} \sum_{u \in U} \frac{1}{\min(K, |R_u|)} \sum_{k=1}^{K} P(k) \cdot rel(k)$$

- **Standard Kaggle/RecSys** : Permet la comparaison avec d'autres Ã©quipes
- **Ã‰quilibre PrÃ©cision/Ordre** : RÃ©compense les bons items ET leur position
- **K=10** : Correspond Ã  une page de rÃ©sultats typique (UX rÃ©aliste)

---

## ğŸ‘¥ 11. Auteurs & CrÃ©dits

**UniversitÃ© Paris 1 PanthÃ©on-Sorbonne â€” Master TIDE**

| Membre | Contributions |
|--------|---------------|
| **Sacha Jocic** | Architecture modÃ¨le, Tuning hyperparamÃ¨tres, Pipeline SVD/SÃ©quentiel |
| **LÃ©a Jouffrey** | Analyse de donnÃ©es (EDA), Logique mÃ©tier, Application Streamlit |
| **Saloua Dekhissi** | Enrichissement sÃ©mantique (ChatGPT), Tests expÃ©rimentaux, Documentation |

---

*Ce projet est l'aboutissement de 2 semaines de recherche intensive sur les systÃ¨mes de recommandation hybrides, inspirÃ© par les solutions gagnantes du Netflix Prize et des compÃ©titions RecSys.*
