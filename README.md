# Syst√®me de Recommandation ‚Äî Documentation du Projet

Ce d√©p√¥t impl√©mente un syst√®me de recommandation hybride "collaboratif + s√©mantique" pour des items (livres), avec un pipeline complet : EDA, entra√Ænement, √©valuation (MAP@K), tuning de param√®tres, enrichissement s√©mantique des m√©tadonn√©es via LLM, et g√©n√©ration de fichier de soumission.

Ce README explique l‚Äôarchitecture, o√π trouver chaque composant, comment ex√©cuter les notebooks/scripts, et comment reproduire les r√©sultats.

---

## 1) Arborescence du projet

```
PythonProject2/
‚îú‚îÄ‚îÄ data/                       # Donn√©es d‚Äôentr√©e et auxiliaires
‚îÇ   ‚îú‚îÄ‚îÄ interactions_train.csv  # Interactions utilisateur‚Äìitem (colonnes attendues: u, i, t)
‚îÇ   ‚îú‚îÄ‚îÄ items.csv               # M√©tadonn√©es des items (Title, Author, Subjects, ...)
‚îÇ   ‚îú‚îÄ‚îÄ items_enriched_ai_turbo.csv  # (optionnel) Items enrichis via LLM
‚îÇ   ‚îî‚îÄ‚îÄ sample_submission.csv # (optionnel) Format d‚ÄôIDs utilisateurs cible pour la soumission
‚îÇ   ‚îî‚îÄ‚îÄ eda/
‚îÇ       ‚îú‚îÄ‚îÄ interactions_by_day.csv                 #output eda table
‚îÇ       ‚îú‚îÄ‚îÄ item_popularity_counts.csv              #output eda table
‚îÇ       ‚îî‚îÄ‚îÄ user_interaction_counts.csv             #output eda table
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_Data_Analysis.ipynb                  # EDA compl√®te des donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ 02_Main_Model_Training.ipynb            # Entra√Ænement + √©valuation du mod√®le de prod
‚îÇ   ‚îú‚îÄ‚îÄ 03_Main_Model_Submission_File_Generator.ipynb # G√©n√©ration du CSV de soumission
‚îÇ   ‚îî‚îÄ‚îÄ 04_All_Experiments.ipynb                # Exp√©riences non concluantes ou abandonn√©es
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py         # Chargement des donn√©es, mapping d‚ÄôIDs, splits temporels
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py               # M√©triques d‚Äô√©valuation (MAP@K)
‚îÇ   ‚îú‚îÄ‚îÄ tuning.py                # Grid search des hyperparam√®tres cl√©s
‚îÇ   ‚îú‚îÄ‚îÄ EnrichissementChatGPT.py # Script d‚Äôenrichissement s√©mantique (OpenAI)
‚îÇ   ‚îî‚îÄ‚îÄ models/
‚îÇ       ‚îú‚îÄ‚îÄ base.py              # Classe abstraite BaseRecommender
‚îÇ       ‚îú‚îÄ‚îÄ production.py        # Mod√®le de production: SemanticHybridRecommender
‚îÇ       ‚îú‚îÄ‚îÄ experimental.py      # Mod√®les alternatifs/ablation/essais
‚îÇ       ‚îî‚îÄ‚îÄ __init__.py          # Exporte les classes de mod√®les
‚îú‚îÄ‚îÄ submission/
‚îÇ   ‚îî‚îÄ‚îÄ (sorties)                # Fichiers de soumission g√©n√©r√©s (ex: submission_final.csv)
‚îú‚îÄ‚îÄ requirements.txt             # D√©pendances Python du projet
‚îî‚îÄ‚îÄ README.md                    # Ce document
```

---

## 2) Donn√©es attendues

- interactions_train.csv (obligatoire)
  - Colonnes minimales: `u` (user id), `i` (item id), `t` (timestamp/ordre)
  - Types: `u` et `i` entiers; `t` num√©rique (ex: epoch sec) ou ordre croissant par utilisateur
- items.csv (recommand√©)
  - Colonnes utiles: `i` (id item), `Title`, `Author`, `Subjects`
  - Ces champs servent √† la repr√©sentation s√©mantique (S-BERT) pour le contenu
- items_enriched_ai_turbo.csv (optionnel)
  - G√©n√©r√© par `src/EnrichissementChatGPT.py`, ajoute `description`, `clean_author`, `category`
  - Peut am√©liorer la composante s√©mantique
- sample_submission.csv (optionnel)
  - Colonne `user_id` pour dicter l‚Äôordre des lignes du fichier final de pr√©dictions

Remarque: `src/preprocessing.py` filtre et aligne `items` avec les `i` pr√©sents dans `interactions` et ajoute `i_idx` (index interne) pour le matching.

---

## 3) Composants principaux

### 3.1 Pr√©traitement ‚Äî `src/preprocessing.py`
- Classe `DataLoader`:
  - Lit les CSV, d√©duplique les interactions, cast `u` et `i` en int.
  - Cr√©e des mappings: `u_map`, `i_map`, `idx_to_i`, et ajoute `u_idx`/`i_idx` aux interactions.
  - Aligne `items` sur les `i` connus et ajoute `i_idx`.
  - Expose `n_users`, `n_items`, `items_df`.
  - Splits temporel par utilisateur via `get_time_split(train_ratio=0.8)` (rang percentile par `t`).
  - `get_full_data()` pour r√©cup√©rer tout le dataset (entra√Ænement final).

### 3.2 Mod√®le de production ‚Äî `src/models/production.py`
- Classe `SemanticHybridRecommender(BaseRecommender)`
  - Id√©e: Hybride "collaboratif + s√©mantique" avec d√©croissance temporelle (time-decay), TF‚ÄëIDF user profiles, similarit√© cosinus, et fusion avec similarit√© s√©mantique issue de S‚ÄëBERT.
  - D√©couplage du signal de re-buy: le boost de r√©-achat est appliqu√© uniquement sur l‚Äôhistorique long-terme pour ne pas diluer les items anciens.
  - √âtapes cl√©s de `fit`:
    1) Encode le texte item via `SentenceTransformer('all-MiniLM-L6-v2')` en combinant `Title`, `Author`, `Subjects`.
    2) Pour chaque demi-vie (`half_life_days`) demand√©e:
       - Calcule poids temporels par interaction; construit matrice sparse utilisateurs√óitems.
       - TF‚ÄëIDF pour profils utilisateurs.
       - Similarit√© collaborative items√óitems via cosinus sur profils transpos√©s.
       - Fusion par `alpha`: `alpha * sim_collab + (1 - alpha) * sim_content`.
    3) Conserve la matrice utilisateur du plus grand half-life comme historique long-terme.
    4) Calcule une popularit√© globale (somme long-terme) pour un l√©ger boost.
  - `predict(k, batch_size)`
    - Agr√®ge les scores des sous-mod√®les (poids `ensemble_weights`).
    - Ajoute un boost re-buy bas√© sur l‚Äôhistorique long-terme (facteur ~1.5).
    - Ajoute un l√©ger boost de popularit√© (0.1 * pop normalis√©e).
    - S√©lectionne le Top‚ÄëK par utilisateur.

Param√®tres efficaces d‚Äôapr√®s exp√©rimentations:
- `alpha ‚âà 0.5`
- `half_life_days = [1, 250]` (tr√®s court vs tr√®s long)
- Des poids d‚Äôensemble non-uniformes peuvent sur-apprendre localement (cf. commentaire sur overfitting dans les notebooks)

### 3.3 Mod√®les exp√©rimentaux ‚Äî `src/models/experimental.py`
- Impl√©mente des variantes/utilitaires pour tests et ablations:
  - `BM25Recommender`: pond√©ration BM25 sur interactions, similarit√© cosinus.
  - `EASERecommender`: m√©thode EASE (r√©gularis√©e) items√óitems.
  - `SVDRecommender`: factorisation basique (SVD tronqu√©e) sur matrice utilisateurs√óitems.
  - `DiversifiedRecommender`: diversification simple des recommandations.
  - `EnsembleHybridRecommender`: variante d‚Äôensemble.
  - `HistoryFilterRecommender`: filtrage sur historique.
  - `LowInteractionRecommender`: strat√©gie pour faibles interactions.
  - `CoupledSemanticRecommender` et `SemanticHybridRecommenderChatGPT`: variantes s√©mantiques coupl√©es.

Toutes h√©ritent de `BaseRecommender` (voir `src/models/base.py`, interface `fit`/`predict`).

### 3.4 M√©triques ‚Äî `src/metrics.py`
- `mapk_score(predicted_indices, true_matrix, k=10)`
  - Calcule MAP@K pour l‚Äô√©valuation hors-ligne avec une matrice v√©rit√©-terrain (CSR ou dense).

### 3.5 Tuning ‚Äî `src/tuning.py`
- Grid search simple sur:
  - `alpha ‚àà [0.2, 0.3, 0.4, 0.5, 0.6, 0.7]`
  - `ensemble_weights ‚àà {[0.7,0.3],[0.5,0.5],[0.6,0.4],[0.8,0.2],[0.9,0.1]}` avec `HALF_LIVES=[30,150]`
- Utilise `DataLoader` pour split temporel; √©value `MAP@10` sur validation.

### 3.6 Enrichissement LLM ‚Äî `src/EnrichissementChatGPT.py`
- Enrichit `items.csv` en batch via l‚ÄôAPI OpenAI (mod√®le `gpt-4o-mini`) pour g√©n√©rer:
  - `description` (FR), `clean_author`, `category`.
- Sauvegarde `items_enriched_ai_turbo.csv`.
- Param√®tres batch et threads contr√¥lent la vitesse; penser aux limites de rate.
- Important: d√©finir la variable d‚Äôenvironnement `OPENAI_API_KEY` et v√©rifier la facturation. Les champs enrichis ne sont utilis√©s que si vous remplacez `items.csv` par le fichier enrichi lors de l‚Äôentra√Ænement/soumission.

---

## 4) Notebooks ‚Äî Guide rapide

1. `01_Data_Analysis.ipynb`
   - EDA compl√®te: qualit√© des donn√©es, distributions, r√©cence, densit√©, long-tail, etc.
2. `02_Main_Model_Training.ipynb`
   - Pipeline de base: chargement via `DataLoader`, split temporel 80/20, entra√Ænement `SemanticHybridRecommender`, pr√©diction `Top‚Äë10`, calcul `MAP@10`.
   - Exemple de configuration performante: `alpha=0.5`, `half_life_days=[1, 250]`.
3. `03_Main_Model_Submission_File_Generator.ipynb`
   - Entra√Ænement sur toutes les donn√©es puis g√©n√©ration du CSV de soumission (format Kaggle: `user_id,recommendation`).
   - G√®re les cold‚Äëstart avec fallback sur les items populaires.
   - Peut utiliser `items_enriched_ai_turbo.csv` si disponible.
4. `04_All_Experiments.ipynb`
   - Journal d‚Äôexp√©riences infructueuses ou abandonn√©es pour la tra√ßabilit√©.

---

## 5) Installation & Pr√©‚Äërequis

- Python 3.9+ recommand√©
- GPU non requis (S‚ÄëBERT mini fonctionne sur CPU) mais acc√©l√®re l‚Äôencodage si disponible

D√©pendances principales (√† ajouter dans `requirements.txt` si besoin):
- numpy, scipy, pandas, scikit-learn
- sentence-transformers
- tqdm
- openai (si enrichissement LLM)
- matplotlib, seaborn (pour EDA)

Exemple d‚Äôinstallation rapide:
```
python -m venv .venv
source .venv/bin/activate  # Ou .venv\Scripts\activate sous Windows
pip install --upgrade pip
pip install numpy scipy pandas scikit-learn sentence-transformers tqdm openai matplotlib seaborn
```

---

## 6) Ex√©cution ‚Äî √âtapes cl√©s

### 6.1 √âvaluation locale (notebook d‚Äôentra√Ænement)
- Ouvrir `notebooks/02_Main_Model_Training.ipynb`
- V√©rifier les chemins `../data/*.csv`
- Lancer toutes les cellules pour entra√Æner et afficher `MAP@10`

### 6.2 Tuning
Depuis `src/` (ou ajuster les imports selon IDE):
```
python src/tuning.py
```
- Le script charge les donn√©es, fait un split, lance le grid search et affiche la meilleure config.

### 6.3 Entra√Ænement complet + Soumission
- Ouvrir `notebooks/03_Main_Model_Submission_File_Generator.ipynb`
- Configurer:
  - `DATA_DIR = '../data'`
  - `BEST_ALPHA = 0.5`
  - `BEST_HALFLIFE = [1, 250]` (ou vos meilleurs hyperparam√®tres)
- Ex√©cuter le notebook pour produire `submission/submission_final.csv`

### 6.4 Enrichissement des items (optionnel)
```
export OPENAI_API_KEY=your_api_key_here
python src/EnrichissementChatGPT.py
# Fichier de sortie: data/items_enriched_ai_turbo.csv
```
- Ensuite, dans vos notebooks, remplacez `items.csv` par `items_enriched_ai_turbo.csv` lors du chargement via `DataLoader`.

---

## 7) D√©tails du format d‚Äô√©valuation

- Construction de la v√©rit√©-terrain validation: on cr√©e une matrice CSR de taille `(n_users, n_items)` avec `1` aux positions `(u_idx, i_idx)` pr√©sentes dans `val_df`.
- `mapk_score` it√®re par utilisateur et calcule la moyenne de la pr√©cision cumul√©e jusqu‚Äô√† `K`.
- Important: `predict` retourne des indices d‚Äôitems internes (`i_idx`). Pour g√©n√©rer des IDs r√©els, convertir via `loader.idx_to_i`.

---

## 8) Bonnes pratiques & pi√®ges courants

- S‚ÄëBERT: n√©cessite `sentence-transformers`. Le premier encodage peut t√©l√©charger le mod√®le.
- M√©moire: l‚Äôencodage de tous les items peut √™tre co√ªteux si `items` est tr√®s grand. Utilisez un mod√®le l√©ger (`all‚ÄëMiniLM‚ÄëL6‚Äëv2`, par d√©faut) et √©ventuellement batcher/mettre en cache.
- Overfitting local: des poids d‚Äôensemble (CT/LT) trop orient√©s vers le set de validation peuvent baisser le score public.
- Cold‚Äëstart: le g√©n√©rateur de soumission g√®re les utilisateurs inconnus via un fallback populaire.
- Alignement IDs: toujours passer des `items` align√©s (avec `i_idx`) au mod√®le; `DataLoader` s‚Äôen charge si les colonnes attendues sont pr√©sentes.
- OpenAI API: stocker la cl√© de mani√®re s√©curis√©e (variables d‚Äôenvironnement), respecter les politiques d‚Äôutilisation. Ne pas committer de cl√©s.

---

## 9) R√©plication rapide (cheat‚Äësheet)

1) Pr√©parer `data/interactions_train.csv` et `data/items.csv`.
2) Lancer `02_Main_Model_Training.ipynb` pour v√©rifier que `MAP@10` est raisonnable.
3) Optionnel: `python src/tuning.py` pour affiner `alpha` et les poids.
4) Entra√Æner sur tout + g√©n√©rer soumission via `03_Main_Model_Submission_File_Generator.ipynb`.
5) Optionnel: enrichir `items` via `src/EnrichissementChatGPT.py` et r√©entra√Æner.

---

## 10) Licence & Cr√©dits

- Code des mod√®les inspir√© de m√©thodes classiques (TF‚ÄëIDF, EASE, SVD) et de l‚Äôencodeur `sentence-transformers`.
- Auteur: Sacha Jocic,L√©a Jouffrey, Saloua Dekhissi

Ce README a √©t√© cr√©√© pour documenter l‚Äôimpl√©mentation et faciliter la prise en main.


---

## 11) R√©sultats (Acad√©miques & Comp√©tition)

### 11.1 Score de comp√©tition
- Plateforme: Kaggle (d√©fi local)
- Score Public: `MAP@10 = 0.17127`
- Rang: `1er`

### 11.2 R√©sultats locaux (validation temporelle 80/20)
R√©√©valuations sur le m√™me split temporel; toutes les approches ci‚Äëdessous sont inf√©rieures au mod√®le final, sauf mention contraire.

| # | Approche                             | MAP@10   | Statut                         |
|---|--------------------------------------|----------|--------------------------------|
| 7 | Coupled Semantic (Re-buy Dilution)   | 0.204524 | Inf√©rieur au Best Model        |
| 8 | Semantic Hybrid (ChatGPT Enriched)   | 0.203973 | Inf√©rieur au Best Model        |
| 3 | Ensemble Short/Long Term             | 0.202633 | Inf√©rieur au Best Model        |
| 0 | BM25 Probabilistic                   | 0.195390 | Inf√©rieur au Best Model        |
| 4 | Diversification (Max 2/Author)       | 0.194026 | Inf√©rieur au Best Model        |
| 6 | Filtre Items Rares (<3 vues)         | 0.163061 | Inf√©rieur au Best Model        |
| 1 | EASE (Linear Model)                  | 0.106677 | Inf√©rieur au Best Model        |
| 2 | SVD (Latent Factors)                 | 0.040002 | Inf√©rieur au Best Model        |
| 5 | Filtre Strict Historique             | 0.020747 | Inf√©rieur au Best Model        |

- Mod√®le final (Production ‚Äî SemanticHybridRecommender, d√©corr√©l√© re‚Äëbuy) : `MAP@10 local = 0.20691`

### 11.3 Progression dans le temps (timeline synth√©tique)
Note: cette timeline est reconstitu√©e a posteriori pour le rapport; les jalons et scores interm√©diaires sont indicatifs.

| Semaine | Jalons principaux                                   | Config cl√©                          | MAP@10 val |
|---------|-----------------------------------------------------|-------------------------------------|------------|
| D1      | EDA, baseline TF‚ÄëIDF users √ó cosinus                | decay=fixe (HL=30)                  | 0.142      |
| D2      | Ajout S‚ÄëBERT (contenu) + fusion Œ±                   | Œ±=0.5, HL=30                        | 0.182      |
| D3      | Ensemble de demi‚Äëvies (CT/LT)                       | HL=[30,150], poids=[0.5,0.5]        | 0.201      |
| D4      | Analyse re‚Äëbuy; correction ¬´decoupled re‚Äëbuy boost¬ª | HL=[1,250], boost re‚Äëbuy long‚Äëterme | 0.206      |
| D5      | Tentatives diversification/contraintes              | ‚Äî                                   | 0.19‚Äì0.20  |
| D6      | Enrichissement LLM (items)                          | Metadata LLM                        | 0.204      |
| D6      | Nettoyage + soumission finale                       | HL=[1,250], Œ±=0.5                   | 0.20691    |
| D7      | Streamlit app                                       | ------                              | pretty     |

‚Äî Ces r√©sultats montrent que la d√©corr√©lation du boost de re‚Äëachat par rapport √† l‚Äôensemble CT/LT est la modification d√©terminante.

---

## 12) Reproductibilit√© & Bonnes pratiques (MAJ)

- Fixer les seeds n‚Äôa pas d‚Äôimpact majeur ici (pas de composantes stochastiques dans le pipeline par d√©faut), mais reste recommand√© pour l‚ÄôEDA/√©chantillonnages.
- Les encodages S‚ÄëBERT peuvent √™tre mis en cache selon votre environnement pour acc√©l√©rer les it√©rations.
- Pour l‚Äôenrichissement LLM:
  - D√©finir la cl√© API via variable d‚Äôenvironnement: `export OPENAI_API_KEY=...`
  - Le script lit d√©sormais la cl√© depuis `OPENAI_API_KEY` et sauvegarde dans `data/items_enriched_ai_turbo.csv`.
  - Respecter les limites de taux (MAX_WORKERS et BATCH_SIZE ajustables) et les politiques d‚Äôusage.

## 13) Limites & Travaux futurs

- Long‚Äëtail: les items tr√®s rares restent difficiles; une r√©gularisation sp√©cifique ou des embeddings supervis√©s pourraient aider.
- Popularit√©: le l√©ger boost global est fixe; on pourrait l‚Äôapprendre ou le conditionner au segment utilisateur.
- S√©rendipit√©/diversit√©: l‚Äôajout de contraintes na√Øves nuit au MAP@K; envisager des objectifs multi‚Äëcrit√®res.
- Cold‚Äëstart utilisateurs: strat√©gies bas√©es sur signaux contextuels (heure, device) ou profils proxy non exploit√©es ici.



## 14) Version finale ‚Äî Sp√©cifications et param√®tres (production.py + 02_Main_Model_Training.ipynb)

Cette section pr√©cise exactement ce que r√©alise la version finale livr√©e du mod√®le de production et r√©capitule les param√®tres utilis√©s dans le notebook d‚Äôentra√Ænement principal.

### 14.1 Mod√®le final: `SemanticHybridRecommender` (src/models/production.py)
- Type: Hybride ¬´ collaboratif + s√©mantique ¬ª avec d√©croissance temporelle, ensemble multi‚Äìdemi‚Äëvies, et boost de re‚Äëachat d√©corr√©l√© (appliqu√© seulement sur l‚Äôhistorique long‚Äëterme).
- Entr√©es attendues de `fit(df_interactions, df_items, ...)`:
  - `df_interactions` avec colonnes: `u_idx`, `i_idx`, `t` (timestamp/ordre). Des duplicats sont possibles, pond√©r√©s ensuite par la r√©cence.
  - `df_items` align√© avec les `i_idx` et colonnes textuelles: `Title`, `Author`, `Subjects` (vides accept√©es, remplies par d√©faut par des cha√Ænes vides avant encodage).

- √âtapes internes de `fit` (sp√©cification):
  1) Encodage s√©mantique items via `SentenceTransformer('all-MiniLM-L6-v2')` sur la concat√©nation ¬´ `Title`. `Author`. `Subjects` ¬ª; calcul d‚Äôune similarit√© de contenu `sim_content` par cosinus des embeddings.
  2) Pour chaque demi‚Äëvie `hl ‚àà half_life_days`:
     - Calcul des poids temporels: `weight = exp(- ln(2) / hl * days_diff)`, avec `days_diff = (last_user_ts - t) / (24*3600)` par utilisateur.
     - Construction d‚Äôune matrice sparse utilisateurs√óitems pond√©r√©e par `weight`.
     - Transformation TF‚ÄëIDF (L2, IDF liss√©) des profils utilisateurs.
     - Similarit√© collaborative items√óitems par cosinus sur la transpos√©e des profils (`user_profile.T`).
     - Fusion par `alpha`: `sim_final = alpha * sim_collaborative + (1 - alpha) * sim_content`.
     - Stockage du sous‚Äëmod√®le dans l‚Äôensemble avec son poids `ensemble_weights[j]` (si non fourni: uniforme).
     - Conservation de la matrice utilisateur du plus grand `hl` comme ¬´ historique long‚Äëterme ¬ª (`long_term_user_matrix`).
  3) Calcul d‚Äôune popularit√© globale: somme des colonnes de `long_term_user_matrix`, normalis√©e sur [0,1].

- √âtapes internes de `predict(k, batch_size)`:
  1) Agr√©gation des scores des sous‚Äëmod√®les: pour chaque batch d‚Äôutilisateurs, on calcule `scores_j = user_batch ¬∑ sim_final_j`, puis `final_scores = Œ£_j weight_j * scores_j`.
  2) Re‚Äëbuy boost (d√©corr√©l√©): `final_scores += 1.5 * long_term_user_matrix_batch` (applique le boost uniquement depuis l‚Äôhistorique long‚Äëterme pour ne pas diluer les vieux favoris).
  3) L√©g√®re popularit√©: `final_scores += 0.1 * pop_scores` (m√™me vecteur pour tous les utilisateurs du batch).
  4) S√©lection Top‚ÄëK: `argpartition` pour extraire les K meilleurs indices `i_idx`, puis tri local par score d√©croissant.

- Remarques importantes:
  - Le boost ¬´ 1.5 ¬ª et le terme de popularit√© ¬´ 0.1 ¬ª sont fixes dans la version livr√©e (et document√©s ici pour la reproductibilit√©).
  - La fusion `alpha` intervient uniquement dans la construction des matrices de similarit√© items√óitems (exploration); le re‚Äëbuy boost est ajout√© apr√®s, √† l‚Äô√©tape de scoring (exploitation).
  - Les demi‚Äëvies tr√®s √©loign√©es (p. ex. `[1, 250]`) permettent de couvrir √† la fois l‚Äôultra‚Äër√©cent et l‚Äôhistorique tr√®s long.

### 14.2 Param√®tres utilis√©s dans `02_Main_Model_Training.ipynb`
- Split temporel: `train_ratio = 0.8` (par utilisateur).
- Mod√®le: `SemanticHybridRecommender(n_users=loader.n_users, n_items=loader.n_items)`.
- Appel d‚Äôentra√Ænement:
  ```text
  # Exemple d'appel (illustratif) :
  # 1) Charger les donn√©es et splitter (train/val)
  # 2) Instancier SemanticHybridRecommender(n_users, n_items)
  # 3) Appeler fit(alpha=0.5, half_life_days=[1, 250]) puis predict(k=10)
  # 4) √âvaluer via MAP@10
  ```
- Pr√©diction: `preds = model.predict(k=10, batch_size=1000)`.
- √âvaluation: `MAP@10` via `mapk_score(preds, val_matrix, k=10)`.

- Valeurs et conventions √† retenir (version livr√©e):
  - `alpha = 0.5`
  - `half_life_days = [1, 250]`
  - `ensemble_weights = None` (donc uniformes)
  - `k = 10`
  - `batch_size = 1000`
  - `re_buy_boost = 1.5` (ajout√© apr√®s l‚Äôagr√©gation des sous‚Äëmod√®les)
  - `popularity_boost = 0.1` (coefficient appliqu√© au vecteur de popularit√© normalis√©)

- Notes pratiques:
  - L‚Äôoption `ensemble_weights=[0.6, 0.4]` a montr√© un meilleur score local mais a d√©grad√© le score Kaggle public, indiquant un sur‚Äëapprentissage au split de validation ‚Äî elle est donc laiss√©e en commentaire dans le notebook.
  - Pour la g√©n√©ration de soumission (`03_Main_Model_Submission_File_Generator.ipynb`), la m√™me configuration est utilis√©e sur l‚Äôensemble des donn√©es (entra√Ænement int√©gral), avec fallback ¬´ items populaires ¬ª pour les utilisateurs cold‚Äëstart.


---

## 15) Application Streamlit ‚Äî D√©monstrateur pour Biblioth√©caire

Cette application autonome permet d‚Äôexplorer le catalogue et de g√©n√©rer des recommandations avec le mod√®le final (`SemanticHybridRecommender`). Elle vise un usage ¬´ pratico‚Äëpratique ¬ª par un/une biblioth√©caire.
Dispo en ligne sur: https://booksystemrecomandersachaleasaloua.streamlit.app/

### 15.1 Installation & Lancement
- Pr√©requis: d√©pendances d√©j√† list√©es dans `requirements.txt` (inclut `streamlit`).
- Installation (si besoin):
  ```
  pip install -r requirements.txt
  ```
- Lancer l‚Äôapplication depuis la racine du d√©p√¥t:
  ```
  streamlit run app/streamlit_app.py
  ```
- Par d√©faut, l‚Äôapp cherchera les fichiers:
  - `data/interactions_train.csv`
  - `data/items_enriched_ai_turbo.csv` (si pr√©sent) ou `data/items.csv`

Astuce: les chemins des CSV sont modifiables dans la barre lat√©rale.

### 15.2 Fonctionnalit√©s principales
- Overview
  - Statistiques rapides (utilisateurs, items, interactions)
  - Recherche rapide par titre/auteur/sujet
- Recommend for Patron (utilisateur connu)
  - S√©lection d‚Äôun `user_id` et g√©n√©ration du Top‚ÄëK
  - R√®gles ¬´ m√©tier ¬ª optionnelles: exclure d√©j√†‚Äëlus, limiter √† N livres par auteur
  - Export CSV des recommandations et recueil de feedback (like) journalis√© dans `data/feedback_log.csv`
- Cold‚ÄëStart (Text Search)
  - Recommandations √† partir d‚Äôune description libre (mots‚Äëcl√©s, auteur, genre)
  - Utilise l‚Äôencodeur s√©mantique S‚ÄëBERT
- Similar Books (item‚Äëitem)
  - Trouver des livres similaires √† un livre choisi (voisinage s√©mantique/collaboratif)
- Analytics
  - Auteurs les plus consult√©s (bar chart), popularit√©, histogrammes de r√©cence
- Settings
  - Visualisation des chemins de donn√©es, g√©n√©ration d‚Äôun CSV de soumission d‚Äôexemple (aper√ßu)

### 15.3 Param√®tres du mod√®le (barre lat√©rale)
- `alpha` (collaboratif vs contenu), `half_life_days` (s√©par√©s par des virgules), `Top‚ÄëK`
- Bouton ¬´ Rebuild model (fit) ¬ª pour refitter avec les nouveaux param√®tres
- Bouton ¬´ Clear caches ¬ª pour r√©initialiser les caches Streamlit

Valeurs par d√©faut: `alpha=0.5`, `half_life_days=[1, 250]`, `k=10`, coh√©rentes avec la version finale document√©e.

### 15.4 Performance & Caching
- Le premier lancement peut √™tre long (t√©l√©chargement du mod√®le S‚ÄëBERT et encodage des items)
- Des caches (`st.cache_data`/`st.cache_resource`) √©vitent les recomputations co√ªteuses
- Un GPU n‚Äôest pas requis mais acc√©l√®re S‚ÄëBERT si disponible

### 15.5 D√©pannage
- ¬´ sentence‚Äëtransformers introuvable ¬ª: installez via `pip install -r requirements.txt`
- Colonne manquante dans `items.csv`: l‚Äôapp tol√®re l‚Äôabsence de `Author`/`Subjects` (remplacement par cha√Æne vide), mais la qualit√© s√©mantique est meilleure avec ces colonnes
- M√©moire: si le catalogue est tr√®s grand, envisagez de r√©duire temporairement `Top‚ÄëK` et de v√©rifier que `items.csv` ne contient pas de colonnes excessives

### 15.6 S√©curit√© & Donn√©es
- L‚Äôapp lit uniquement des CSV locaux; aucun envoi de donn√©es n‚Äôest r√©alis√©
- Les feedbacks sont stock√©s en local dans `data/feedback_log.csv`


### 15.7 Streamlit too heavy ‚Üí Persist item embeddings to disk

I implemented robust on‚Äëdisk caching for S‚ÄëBERT item embeddings so the app no longer recomputes them every run. This dramatically reduces CPU/RAM usage and startup time.



#### What changed
- `src/models/production.py`
  - Added disk cache for item embeddings during `fit(...)`:
    - Builds a stable text "soup" per item (`Title`. `Author`. `Subjects`) sorted by `i_idx`.
    - Hashes content (`md5`) together with model name (`all-MiniLM-L6-v2`).
    - Loads embeddings from `data/cache/embeddings_{model}_{hash}.npy` if present; otherwise encodes once and saves `.npy` + `.json` metadata.
  - More robust handling when `Title`/`Author`/`Subjects` columns are missing (falls back to empty strings).

- `app/streamlit_app.py`
  - Caching upgraded for app‚Äëside semantic features (Cold‚ÄëStart search, Similar Books):
    - `compute_item_embeddings(items_df, use_disk_cache=True)` uses the same disk cache scheme.
    - New sidebar toggle: ‚ÄúUse disk cache for embeddings‚Äù (default ON).
    - New sidebar action: ‚ÄúClear embedding disk cache‚Äù to delete cached `.npy`/`.json` files.
    - Existing ‚ÄúClear in‚Äëmemory caches‚Äù still clears Streamlit caches.

#### Why this fixes the issue
- The embeddings are the heavy step; now they‚Äôre encoded once and reused across sessions/runs.
- On subsequent app starts, the app directly memory‚Äëmaps or loads the saved `.npy` instead of recomputing, saving minutes and RAM spikes.

#### How to use
1) Install deps: `pip install -r requirements.txt`.
2) Run the app: `streamlit run app/streamlit_app.py`.
3) Ensure the sidebar toggle ‚ÄúUse disk cache for embeddings‚Äù is ON (default).
4) First run computes and saves to `data/cache/`; next runs should be instant.
5) If you change `items` content significantly, the cache automatically invalidates via content hash.
6) To force a rebuild, click ‚ÄúClear embedding disk cache‚Äù (and optionally ‚ÄúRebuild model (fit)‚Äù).

#### Notes
- Cache paths: `data/cache/embeddings_all-MiniLM-L6-v2_<md5>.npy` + `.json`.
- The production model (`fit`) and the Streamlit app both use compatible caching, so training and UI share the same saved embeddings if the items content matches.
- If the dataset is extremely large, consider keeping the disk cache on a fast drive (SSD) for best load times.

## 15.8 Am√©lioration de secours au cas ou qqn nous bats dans kaggle, on en a encore dans le sac
# üìà Analyse et Strat√©gies d'Am√©lioration pour le Syst√®me de Recommandation (Comp√©tition Kaggle)

Cette analyse propose une s√©rie d'am√©liorations visant √† maximiser la performance du mod√®le de recommandation en production (combinant time-decay, TF-IDF collaboratif, S-BERT s√©mantique, et boosts sp√©cifiques) en vue d'une augmentation du score **MAP@10** (Mean Average Precision at 10).

L'objectif est d'identifier des leviers d'optimisation, class√©s par retour sur investissement (ROI) estim√©, pour consolider ou am√©liorer le classement dans la comp√©tition.

---

## I. Optimisations Fines des Hyperparam√®tres (Quick Wins)
*Ces ajustements, n√©cessitant un faible effort, se concentrent sur la calibration des param√®tres d'agr√©gation et d'exploration.*

| Am√©lioration | Description de l'Action | Justification Th√©orique | Œî MAP@10 Estim√© |
| :--- | :--- | :--- | :--- |
| **1. Affinement de l'exposant de d√©c√©l√©ration ($Œ±$)** | √âlargissement de la grille de recherche de l'exposant $Œ±$ (e.g., `{0.35, 0.45, 0.55, 0.65}`) et introduction d'une **demi-vie temporelle m√©diane** (e.g., 30 jours) au m√©lange existant (1 et 250 jours). | Les sch√©mas de consommation interm√©diaires peuvent capturer une m√©moire s√©mantique utile. Un $Œ±$ optimis√© maximise la pertinence des interactions r√©centes. | `+0.002` √† `+0.006` |
| **2. Calibration des coefficients de boost** | Balayage syst√©matique des coefficients de **r√©achat** (*re-buy*) et de **popularit√©** (*pop*) autour des valeurs nominales. <br> Ex: $re\_buy \in \{1.2, 1.35, 1.65\}$ ; $pop \in \{0.05, 0.15\}$. | Assurer un √©quilibre optimal entre l'exploitation des pr√©f√©rences existantes et la d√©couverte, √©vitant le surapprentissage sur l'historique utilisateur. | `+0.001` √† `+0.003` |
| **3. Introduction d'un √©cart temporel (no-leakage gap)** | Suppression d'une petite fen√™tre d'interactions (e.g., 2‚àí3%) autour de la fronti√®re temporelle entre l'ensemble d'entra√Ænement et de validation. | R√©duit le risque de fuite d'information (*temporal leakage*) pour les interactions imm√©diatement cons√©cutives. Rend le score local plus fid√®le au Test Public. | **Score local plus robuste** |

---

## II. Am√©lioration de la Qualit√© et Stabilit√© des Similarit√©s Inter-Items
*La stabilit√© et la robustesse de la matrice de similarit√© inter-items sont critiques, en particulier face au bruit et aux long-tails.*

| Am√©lioration | Description de l'Action | Justification Th√©orique | Œî MAP@10 Estim√© |
| :--- | :--- | :--- | :--- |
| **4. √âlagage (Pruning) Top-K et R√©duction de Bruit (Shrinkage)** | 1. **Top-K:** Conserver uniquement les $K$ voisins (e.g., $K \in \{100, 200, 400\}$).<br>2. **Shrinkage:** Appliquer la formule :<br> $$sim_{shrink} = sim \times \frac{n_{cooc}}{n_{cooc} + \lambda}$$ <br> o√π $\lambda$ est un hyperparam√®tre de r√©gularisation. | Le Top-K minimise l'impact des similarit√©s bruit√©es. Le shrinkage pond√®re √† la baisse les similarit√©s issues d'un faible support statistique ($n_{cooc}$ faible), stabilisant les items rares. | `+0.002` √† `+0.010` |
| **5. Pond√©ration de fusion ($Œ±$) adaptative** | Utiliser un $\alpha_{eff}$ tel que $\alpha_{eff} = r \times \alpha$, o√π $r$ d√©pend de la densit√© de co-occurrence ($n_{cooc}$) ou par segmentation en bacs. | Dans les cas de faible preuve collaborative (*cold/rare items*), le mod√®le s√©mantique (S-BERT) prend le relais. Permet une fusion dynamique adapt√©e au contexte. | `+0.002` √† `+0.006` |

---

## III. Am√©lioration de l'Encodage S√©mantique (Contenu)
*L'optimisation des repr√©sentations vectorielles par S-BERT est un levier de gain "s√ªr".*

| Am√©lioration | Description de l'Action | Justification Th√©orique | Œî MAP@10 Estim√© |
| :--- | :--- | :--- | :--- |
| **6. Pond√©ration des champs de contenu (Text Soup)** | Assigner des poids aux champs pour l'encodeur. <br>Ex: $2 \times Titre + 1 \times Auteur + 1 \times Sujets + 0.5 \times Desc$. | Le Titre est souvent plus informatif et concis (signal fort), tandis qu'une description longue peut introduire du bruit, justifiant un poids moindre. | `+0.002` √† `+0.006` |
| **7. Exploration d'encodeurs s√©mantiques alternatifs** | Tester des mod√®les S-BERT alternatifs pr√©-entra√Æn√©s pour la recherche s√©mantique (ex: `multi-qa-MiniLM-L6-cos-v1`, `all-MiniLM-L12-v2`). | Ces mod√®les sont optimis√©s sur des t√¢ches de similarit√© inter-document tr√®s proches de l'objectif final, capturant mieux les nuances s√©mantiques. | `+0.002` √† `+0.008` |

---

## IV. Adaptation Personnalis√©e par Segments d'Utilisateurs
*L'h√©t√©rog√©n√©it√© de la population n√©cessite une personnalisation au-del√† du simple produit scalaire.*

| Am√©lioration | Description de l'Action | Justification Th√©orique | Œî MAP@10 Estim√© |
| :--- | :--- | :--- | :--- |
| **8. $Œ±$ adaptatif par profil d'activit√©** | Segmenter les utilisateurs (L√©ger $\le 3$, Moyen $4-20$, Dense $>20$). Assigner un $\alpha$ sp√©cifique (ex: $\{0.2, 0.4, 0.6\}$). | Les utilisateurs "denses" b√©n√©ficient des signaux collaboratifs ($\alpha$ √©lev√©), tandis que les "l√©gers" (*cold-start*) reposent plus sur le contenu s√©mantique ($\alpha$ faible). | `+0.003` √† `+0.012` |

---

## V. Re-classement (Re-ranking) Mod√©r√© et Robustesse
*Ajustements post-score pour am√©liorer l'exp√©rience utilisateur sans d√©grader la m√©trique.*

| Am√©lioration | Description de l'Action | Justification Th√©orique | Œî MAP@10 Estim√© |
| :--- | :--- | :--- | :--- |
| **9. P√©nalit√© douce de l'Auteur dans le Top-K** | Appliquer une p√©nalit√© soustractive mod√©r√©e ($\gamma \in \{0.01, 0.02\}$) si un auteur est sur-repr√©sent√© (ex: $\ge 3$ fois) dans le Top-K. | Offre une diversit√© contr√¥l√©e (*Exposure Fairness*) sans imposer une contrainte binaire rigide qui d√©grade la pr√©cision. | **Neutre √† L√©g√®rement positif** |

---

## VI. Strat√©gie de Validation et Stabilit√©
*Essentiel pour √©viter le sur-ajustement local.*

| Am√©lioration | Description de l'Action | Justification Th√©orique |
| :--- | :--- | :--- |
| **10. Validation Crois√©e Temporelle Glissante (Rolling CV)** | Ex√©cuter sur $\ge 3$ tranches temporelles ($Train T_n \to Val T_n \to T_{n+\Delta}$). Valider si gain stable ($\ge 2/3$ folds) et significatif ($\ge 0.003$). | Simule l'√©volution temporelle du jeu de donn√©es Kaggle, garantissant que les hyperparam√®tres ne sont pas sp√©cifiques √† une unique p√©riode ("lucky shot"). |
| **11. Politique Cold-Start par popularit√© r√©cente** | Utiliser la popularit√© sur une fen√™tre r√©cente (30‚àí60 jours) au lieu de globale pour les nouveaux utilisateurs. | Refl√®te mieux les tendances actuelles (trends) que la popularit√© historique globale. |

---

## VII. Plan de Priorisation (Ordre de Test Recommand√©)

1.  **Ajustements Rapides :** $Œ±$ et demi-vie m√©diane (I-1) ‚Üí Calibration des boosts (I-2) ‚Üí √âlagage Top-K (II-4).
2.  **Qualit√© et Contenu :** Pond√©ration du *text soup* (III-6) ‚Üí Encodeur alternatif (III-7) ‚Üí $Œ±$ adaptatif par segment (IV-8) ‚Üí Shrinkage/Fusion adaptative (II-4/II-5).
3.  **Robustesse :** Application du *Rolling CV* (VI-10) pour valider les gains ‚Üí Test du re-ranking doux (V-9).

### üéØ Objectif R√©aliste de Gain
L'addition de 3 √† 5 de ces leviers, s'ils sont bien calibr√©s et d√©montrent un gain stable en Rolling CV, devrait permettre un gain de **+0.006 √† +0.020** en MAP@10 local.
