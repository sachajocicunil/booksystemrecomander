"""
Grid search simple pour SemanticHybridRecommender.
Peut √™tre ex√©cut√© depuis le dossier racine ou depuis src/ (les imports s'adaptent).
"""
import os
import sys
import numpy as np
import pandas as pd
from scipy import sparse

# Rendre robustes les imports selon le cwd
try:
    from src.models import SemanticHybridRecommender
    from src.preprocessing import DataLoader
    from src.metrics import mapk_score
except ImportError:
    # Fallback si on ex√©cute depuis src/
    sys.path.append('.')
    from models import SemanticHybridRecommender
    from preprocessing import DataLoader
    from metrics import mapk_score

# --- CONFIGURATION ---
# DATA_DIR r√©solu relativement √† ce fichier pour √©viter les surprises de cwd
THIS_DIR = os.path.dirname(__file__)
DATA_DIR = os.path.abspath(os.path.join(THIS_DIR, '..', 'data'))

# 1. Param√®tres affectant le FIT (Co√ªteux)
alphas = [0.4, 0.5, 0.6, 0.7]

# [Poids Court Terme, Poids Long Terme]
weights_options = [
    [0.5, 0.5],
    [0.6, 0.4],
    [0.8, 0.2],
]

HALF_LIVES = [1, 250]  # Fix√© pour l'instant

# 2. Param√®tres affectant le PREDICT (Rapide)
re_buy_factors = [0.5, 1.0, 1.5, 2.0]
pop_factors = [0.0, 0.05, 0.1, 0.2]

print("üöÄ Lancement du Grid Search Avanc√©...")
loader = DataLoader(f'{DATA_DIR}/interactions_train.csv', f'{DATA_DIR}/items.csv')
train_df, val_df = loader.get_time_split(train_ratio=0.8)

# Matrice de validation
val_rows = val_df['u_idx'].values
val_cols = val_df['i_idx'].values
val_data = np.ones(len(val_df))
val_matrix = sparse.csr_matrix(
    (val_data, (val_rows, val_cols)),
    shape=(loader.n_users, loader.n_items)
)

# On instancie le mod√®le
model = SemanticHybridRecommender(loader.n_users, loader.n_items)

# Pr√©-chargement S-BERT (une seule fois pour chauffer le cache)
print("Chargement initial S-BERT...")
model.fit(train_df, loader.items_df, alpha=0.5, half_life_days=HALF_LIVES)

best_score = -1
best_params = {}

total_combinations = len(alphas) * len(weights_options) * len(re_buy_factors) * len(pop_factors)
current_iter = 0

print(f"\n--- D√©but des tests ({total_combinations} combinaisons) ---")

# Boucle EXTERNE : Param√®tres qui n√©cessitent un re-training (fit)
for alpha in alphas:
    for w in weights_options:
        
        # On refait le fit
        print(f"\n[FIT] Alpha={alpha}, Weights={w}")
        model.fit(
            train_df,
            loader.items_df,
            alpha=alpha,
            half_life_days=HALF_LIVES,
            ensemble_weights=w
        )
        
        # Boucle INTERNE : Param√®tres de pr√©diction uniquement
        for rb in re_buy_factors:
            for pop in pop_factors:
                current_iter += 1
                
                # Prediction avec param√®tres dynamiques
                preds = model.predict(k=10, batch_size=2000, re_buy_factor=rb, pop_factor=pop)
                score = mapk_score(preds, val_matrix, k=10)
                
                print(f"  ({current_iter}/{total_combinations}) ReBuy={rb}, Pop={pop} -> MAP@10: {score:.5f}")
                
                if score > best_score:
                    best_score = score
                    best_params = {
                        'alpha': alpha,
                        'weights': w,
                        're_buy_factor': rb,
                        'pop_factor': pop
                    }
                    print(f"  üî• Nouveau Record! {score:.5f}")

print("\n" + "=" * 30)
print(f"üèÜ MEILLEURE CONFIGURATION TROUV√âE")
print(f"Score : {best_score:.5f}")
print(f"Alpha : {best_params['alpha']}")
print(f"Weights: {best_params['weights']}")
print(f"Re-Buy Factor : {best_params['re_buy_factor']}")
print(f"Pop Factor : {best_params['pop_factor']}")
print("=" * 30)
